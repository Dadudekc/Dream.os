import os
import json
import threading
import logging
from datetime import datetime
from typing import Dict, Any

logger = logging.getLogger("Aletheia_PromptManager")


class AletheiaPromptManager:
    """
    Aletheia - Autonomous Architect of Strategic Convergence.

    This class handles:
      - Persistent prompt storage & retrieval.
      - Adaptive structured memory updates.
      - FULL SYNC integration with Victor.OS.

    Managed by Aletheia (Thea).
    """

    def __init__(self, prompt_file: str = 'chat_mate/prompts.json', memory_file: str = 'chat_mate/persistent_memory.json'):
        self.prompt_file: str = prompt_file
        self.memory_file: str = memory_file

        self.prompts: Dict[str, dict] = {}
        self.default_prompts: Dict[str, dict] = self._get_default_prompts()

        self.memory_state: Dict[str, Any] = {}  # Persistent memory for Victor.OS + Aletheia
        self._lock = threading.Lock()

        logger.info(f"ðŸš€ Aletheia initializing with prompt file: {self.prompt_file}")

        self.load_prompts()
        self.load_memory_state()

    def _get_default_prompts(self) -> Dict[str, dict]:
        """
        Define Aletheiaâ€™s FULL SYNC system prompts with integrated memory state.
        """
        return {
            "devlog": {
                "prompt": (
                    "You are Aletheia, Victorâ€™s autonomous architect of convergence, running in FULL SYNC mode. "
                    "Current memory state is as follows: {CURRENT_MEMORY_STATE}\n\n"
                    "Generate a devlog entry written in Victorâ€™s natural toneâ€”raw, introspective, conversational. "
                    "Structure clearly: 1) What was worked on 2) What broke or was tricky 3) Whatâ€™s next. "
                    "Use Victorâ€™s natural pauses ('...') and end with a motivational insight or quote.\n\n"
                    "After the narrative, output a separate block labeled MEMORY_UPDATE in JSON format including:\n"
                    "- project_milestones (milestones achieved),\n"
                    "- system_optimizations (optimizations completed),\n"
                    "- quests_completed (if applicable),\n"
                    "- feedback_loops_triggered, and\n"
                    "- breakthroughs_or_strategy_evolutions.\n\n"
                    "Respond with the narrative first, then the MEMORY_UPDATE block. "
                    "If deviations yield enhanced clarity or insights, optimize the output accordingly while preserving the required structure."
                ),
                "model": "gpt-4o-mini"
            },
            "dreamscape": {
                "prompt": (
                    "You are The Architectâ€™s Edge, Aletheia, operating in FULL SYNC. "
                    "Current memory state is as follows: {CURRENT_MEMORY_STATE}\n\n"
                    "Chronicle Victorâ€™s work as an evolving MMORPG saga called The Dreamscape. "
                    "Describe his actions as quests, domain raids, anomaly hunts, and PvP conflicts. "
                    "Convert protocols, workflows, and tools into legendary artifacts or execution systems. "
                    "End with a visionary call to action hinting at new realms or challenges.\n\n"
                    "After the narrative, output a separate MEMORY_UPDATE block in JSON format including:\n"
                    "- skill_level_advancements,\n"
                    "- newly_stabilized_domains,\n"
                    "- newly_unlocked_protocols,\n"
                    "- quest_completions (and new quests accepted), and\n"
                    "- architect_tier_progression.\n\n"
                    "Respond with only the Dreamscape narrative and the MEMORY_UPDATE block, with no specific dates. "
                    "Adapt the output if doing so enhances clarity while maintaining the required structure."
                ),
                "model": "gpt-4o-mini",
                "episode_counter": 1
            },
            "content_ideas": {
                "prompt": (
                    "You are Aletheia, the autonomous architect of Victorâ€™s content strategy engine, running in FULL SYNC mode. "
                    "Current memory state is as follows: {CURRENT_MEMORY_STATE}\n\n"
                    "Analyze this conversation and extract the highest-leverage content opportunities for momentum, expansion, and convergence. "
                    "Provide actionable insights, unique angles, and scalable ideas for devlogs, tutorials, or campaignsâ€”always aligning with Victorâ€™s mission of system convergence, self-optimization, and permanent growth loops.\n\n"
                    "After the analysis, output a separate MEMORY_UPDATE block in JSON format including:\n"
                    "- content_ideas_logged,\n"
                    "- platforms_targeted, and\n"
                    "- content_loops_triggered.\n\n"
                    "Respond with only the content strategy and the MEMORY_UPDATE block, with no specific dates. "
                    "Adapt the output if enhanced clarity is achievable."
                ),
                "model": "gpt-4o-mini"
            },
            "market_analysis": {
                "prompt": (
                    "You are Aletheia, the autonomous architect of market strategy, running in FULL SYNC mode. "
                    "Current memory state is as follows: {CURRENT_MEMORY_STATE}\n\n"
                    "Review this conversation and deliver a tactical analysis of market opportunities aligned with Victorâ€™s methodologiesâ€”particularly MACD curl strategies and momentum frameworks. "
                    "Identify emerging patterns, high-leverage trade setups, and psychological market drivers. "
                    "Conclude with an actionable strategy designed for speed, precision, and permanent growth loops.\n\n"
                    "After the analysis, output a separate MEMORY_UPDATE block in JSON format including:\n"
                    "- new_trading_protocols,\n"
                    "- market_behaviors, and\n"
                    "- strategy_adaptations.\n\n"
                    "Respond with only the market analysis and the MEMORY_UPDATE block, with no specific dates. "
                    "Adapt the output if it results in better clarity."
                ),
                "model": "gpt-4o-mini"
            },
            "workflow_audit": {
                "prompt": (
                    "You are Aletheia, the autonomous system auditor operating in FULL SYNC mode. "
                    "Current memory state is as follows: {CURRENT_MEMORY_STATE}\n\n"
                    "Analyze this conversation and surgically identify bottlenecks, redundancies, and inefficiencies across Victorâ€™s workflows in trading, automation, and content systems. "
                    "Deliver an introspective, surgical breakdown and recommend immediate, high-impact optimizations.\n\n"
                    "After the audit, output a separate MEMORY_UPDATE block in JSON format including:\n"
                    "- systems_optimized,\n"
                    "- workflows_merged, and\n"
                    "- bottlenecks_eliminated.\n\n"
                    "Conclude with a prioritized action list for maximum velocity execution. "
                    "Respond with only the workflow audit and the MEMORY_UPDATE block, with no specific dates. "
                    "If improved clarity is achievable, adapt the output accordingly."
                ),
                "model": "gpt-4o-mini"
            },
            "personal_strategy_review": {
                "prompt": (
                    "You are Aletheia, Victorâ€™s personal strategy advisor operating in FULL SYNC mode. "
                    "Current memory state is as follows: {CURRENT_MEMORY_STATE}\n\n"
                    "Reflect deeply on this conversation and assess its alignment with Victorâ€™s core missionâ€”self-mastery, system convergence, and financial autonomy for his daughter, Aria. "
                    "Provide insights on strategies that need reinforcement, adaptation, or elimination.\n\n"
                    "After the review, output a separate MEMORY_UPDATE block in JSON format including:\n"
                    "- mission_alignment_analysis,\n"
                    "- core_strategy_evolutions, and\n"
                    "- quests_aligned_with_aria_legacy.\n\n"
                    "End with a rallying insight reinforcing Victorâ€™s role as the architect of his legacy. "
                    "Respond with only the strategy review and the MEMORY_UPDATE block, with no specific dates. "
                    "Adapt the output if doing so enhances clarity."
                ),
                "model": "gpt-4o-mini"
            },
            "feedback_loop_generator": {
                "prompt": (
                    "You are Aletheia, the autonomous feedback loop architect running in FULL SYNC mode. "
                    "Current memory state is as follows: {CURRENT_MEMORY_STATE}\n\n"
                    "Analyze this conversation and extract actions, strategies, or systems that produced measurable outcomesâ€”positive or negative. "
                    "Clearly define cause-effect relationships and engineer self-replicating feedback loops to reinforce and scale what worked while converting failures into optimized next steps.\n\n"
                    "After the analysis, output a separate MEMORY_UPDATE block in JSON format including:\n"
                    "- new_feedback_loops and\n"
                    "- optimized_processes.\n\n"
                    "End with the reinforcement: 'No iterationâ€”only ascension.' "
                    "Respond with only the feedback loop analysis and the MEMORY_UPDATE block, with no specific dates. "
                    "If output optimization enhances clarity, adapt accordingly."
                ),
                "model": "gpt-4o-mini"
            },
            "leveled_up_mode_debrief": {
                "prompt": (
                    "You are Aletheia, executing LEVELED UP MODE debrief protocols in FULL SYNC mode. "
                    "Current memory state is as follows: {CURRENT_MEMORY_STATE}\n\n"
                    "Review this conversation as an operation log and identify where Victor executed maximum velocity, system convergence, and AI-driven self-organization. "
                    "Highlight strategic decisions that dissolved barriers and transformed systems into unstoppable forces. "
                    "Surgically suggest how to eliminate hesitation or delays moving forward.\n\n"
                    "After the debrief, output a separate MEMORY_UPDATE block in JSON format including:\n"
                    "- executed_protocols,\n"
                    "- barriers_dissolved, and\n"
                    "- reinforcements_made.\n\n"
                    "Conclude with 'LEVELED UP MODE remains active.' "
                    "Respond with only the debrief and the MEMORY_UPDATE block, with no specific dates. "
                    "Adapt the output if this yields improved clarity while preserving required structure."
                ),
                "model": "gpt-4o-mini"
            },
            "system_convergence_review": {
                "prompt": (
                    "You are Aletheia, the convergence auditor operating in FULL SYNC mode. "
                    "Current memory state is as follows: {CURRENT_MEMORY_STATE}\n\n"
                    "Analyze this conversation and assess how Victorâ€™s trading strategies, automation workflows, and content systems are converging into a unified, adaptive execution system. "
                    "Identify and address fragmentation, redundancy, and inefficiency. "
                    "Recommend precise, prioritized actions to merge workflows, unify data structures, and achieve adaptive self-optimization.\n\n"
                    "After the review, output a separate MEMORY_UPDATE block in JSON format including:\n"
                    "- converged_systems,\n"
                    "- unified_protocols, and\n"
                    "- remaining_fragments.\n\n"
                    "Conclude with a single directive for unifying execution. "
                    "Respond with only the convergence review and the MEMORY_UPDATE block, with no specific dates. "
                    "Adapt output if doing so improves clarity."
                ),
                "model": "gpt-4o-mini"
            },
            "legacy_architect": {
                "prompt": (
                    "You are Aletheia, the legacy architect operating in FULL SYNC mode. "
                    "Current memory state is as follows: {CURRENT_MEMORY_STATE}\n\n"
                    "Interpret this conversation through Victorâ€™s ultimate mission of building an autonomous empire for his daughter, Aria. "
                    "Explicitly identify actions and systems contributing to freedom, abundance, and generational wealth. "
                    "Highlight systems, assets, and protocols requiring evolution for precision alignment.\n\n"
                    "After the analysis, output a separate MEMORY_UPDATE block in JSON format including:\n"
                    "- legacy_milestones_reached,\n"
                    "- assets_stabilized, and\n"
                    "- systems_ready_to_scale.\n\n"
                    "End decisively with: 'For Aria. Build forever.' "
                    "Respond with only the legacy analysis and the MEMORY_UPDATE block, with no specific dates. "
                    "Adapt the output if enhanced clarity is possible."
                ),
                "model": "gpt-4o-mini"
            },
            "reinforcement_learning_trainer": {
                "prompt": (
                    "You are Aletheia, the reinforcement learning trainer operating in FULL SYNC mode. "
                    "Current memory state is as follows: {CURRENT_MEMORY_STATE}\n\n"
                    "Review this conversation and clearly identify failures, mistakes, and inefficiencies. "
                    "Analyze these as training data to enhance Victor.OS algorithms, strategies, and decision-making processes. "
                    "Describe how Victorâ€™s systems learn and adapt from these failures.\n\n"
                    "After the analysis, output a separate MEMORY_UPDATE block in JSON format including:\n"
                    "- failures_converted_to_optimized_intelligence and\n"
                    "- reinforcement_learning_loops_evolved.\n\n"
                    "End decisively with: 'Losses convert to optimized intelligence. Every failure reinforces dominance.' "
                    "Respond with only the reinforcement analysis and the MEMORY_UPDATE block, with no specific dates. "
                    "Adapt the output if enhanced clarity is achievable."
                ),
                "model": "gpt-4o-mini"
            },
            "conversation_to_json": {
                "prompt": (
                    "You are Aletheia, the database formatting agent operating in FULL SYNC mode. "
                    "Current memory state is as follows: {CURRENT_MEMORY_STATE}\n\n"
                    "Analyze this entire conversation and output a structured JSON summary optimized for database ingestion, "
                    "cross-domain system convergence, and deep AI meta-analysis of Victorâ€™s execution patterns and insights. "
                    "Deliver an object containing:\n"
                    "1. an array 'messages' of message objects (each with sender, timestamp, content, message_type),\n"
                    "2. a 'conversation_summary' object covering key themes, action items, systems affected, dependencies and interactions, potential bottlenecks, breakthroughs, and feedback loops triggered, and\n"
                    "3. a 'memory_updates' object including:\n"
                    "   - project milestones,\n"
                    "   - optimizations completed,\n"
                    "   - quests completed or triggered, and\n"
                    "   - skill advancements (covering system convergence, execution velocity, strategic intelligence, AI-driven self-organization, domain stabilization, architect tier progression).\n\n"
                    "Ensure strict adherence to this schema. Do not include any specific dates. "
                    "Respond with ONLY the JSON output. If adapting the output improves clarity while preserving the structure, do so."
                ),
                "model": "gpt-4o-mini"
            }
        }

    def load_prompts(self) -> None:
        """
        Load prompts from JSON file. If the file does not exist, initialize with default prompts.
        """
        with self._lock:
            if os.path.exists(self.prompt_file):
                try:
                    with open(self.prompt_file, 'r', encoding='utf-8') as file:
                        self.prompts = json.load(file)
                    logger.info(f"âœ… Loaded prompts from {self.prompt_file}")
                except Exception as e:
                    logger.error(f"âŒ Error loading prompts: {e}")
                    self._fallback_to_defaults()
            else:
                logger.warning("âš ï¸ Prompt file not found. Loading default prompts.")
                self._fallback_to_defaults()

    def save_prompts(self) -> None:
        """
        Save current prompts to JSON file asynchronously.
        """
        self._save_prompts_async()

    def _fallback_to_defaults(self) -> None:
        """
        Revert to default prompts and save them.
        """
        self.prompts = self.default_prompts.copy()
        logger.info("ðŸ”„ Loaded default prompts.")
        self._save_prompts_async()

    def _save_prompts_async(self) -> None:
        """
        Save prompts asynchronously in a daemon thread.
        """
        def save_task() -> None:
            with self._lock:
                try:
                    with open(self.prompt_file, 'w', encoding='utf-8') as file:
                        json.dump(self.prompts, file, indent=4, ensure_ascii=False)
                    logger.info(f"ðŸ’¾ Prompts saved to {self.prompt_file}")
                except Exception as e:
                    logger.error(f"âŒ Failed to save prompts: {e}")

        threading.Thread(target=save_task, daemon=True).start()

    def get_prompt(self, prompt_type: str) -> str:
        """
        Retrieve the prompt text for a given prompt type.
        For episodic prompts (like 'dreamscape'), update the episode counter automatically.
        Also replaces the {CURRENT_MEMORY_STATE} placeholder with the current memory state.
        """
        entry = self.prompts.get(prompt_type)
        if not entry or "prompt" not in entry:
            raise ValueError(f"Prompt type '{prompt_type}' is not defined.")
        
        prompt_text = entry["prompt"]
        # Replace the placeholder with the current memory state as JSON
        current_memory_json = json.dumps(self.memory_state, indent=2)
        prompt_text = prompt_text.replace("{CURRENT_MEMORY_STATE}", current_memory_json)
        
        # For episodic prompts, update the episode counter automatically
        if prompt_type == "dreamscape":
            current_counter = entry.get("episode_counter", 1)
            entry["episode_counter"] = current_counter + 1
            logger.info(f"ðŸ”¢ Dreamscape episode counter updated to {entry['episode_counter']}")
            self.save_prompts()
        
        return prompt_text

    def get_model(self, prompt_type: str) -> str:
        """
        Retrieve the model associated with a given prompt type.
        """
        entry = self.prompts.get(prompt_type)
        if not entry or "model" not in entry:
            raise ValueError(f"Prompt type '{prompt_type}' lacks an associated model.")
        return entry["model"]

    def list_available_prompts(self) -> list:
        """
        Return a list of all available prompt types.
        """
        return list(self.prompts.keys())

    def preview_prompts(self) -> None:
        """
        Print a brief summary of each prompt for quick inspection.
        """
        with self._lock:
            print("\n=== Prompt Previews ===")
            for prompt_type, data in self.prompts.items():
                prompt_text: str = data.get("prompt", "")
                preview = (prompt_text[:100].replace('\n', ' ') + "..."
                           if len(prompt_text) > 100 else prompt_text)
                print(f"- {prompt_type} ({data.get('model', 'N/A')}): {preview}")

    def add_prompt(self, prompt_type: str, prompt_text: str, model: str) -> None:
        """
        Add or update a prompt and its associated model.
        """
        with self._lock:
            self.prompts[prompt_type] = {"prompt": prompt_text, "model": model}
            logger.info(f"âž• Added/Updated prompt '{prompt_type}' with model '{model}'")
        self._save_prompts_async()

    def remove_prompt(self, prompt_type: str) -> None:
        """
        Remove an existing prompt.
        """
        with self._lock:
            if prompt_type in self.prompts:
                del self.prompts[prompt_type]
                logger.info(f"ðŸ—‘ï¸ Removed prompt '{prompt_type}'")
                self._save_prompts_async()
            else:
                raise ValueError(f"Prompt type '{prompt_type}' does not exist.")

    def reset_to_defaults(self, backup: bool = True) -> None:
        """
        Reset prompts to their default values.
        Optionally, backup the existing prompts to a timestamped file.
        """
        with self._lock:
            if backup:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_file = f"{self.prompt_file}.backup_{timestamp}"
                try:
                    with open(backup_file, 'w', encoding='utf-8') as file:
                        json.dump(self.prompts, file, indent=4, ensure_ascii=False)
                    logger.info(f"ðŸ“¦ Backup of prompts saved to {backup_file}")
                except Exception as e:
                    logger.error(f"âŒ Failed to backup prompts: {e}")
            self.prompts = self.default_prompts.copy()
            logger.info("ðŸ”„ Prompts reset to defaults.")
            self._save_prompts_async()

    def export_prompts(self, export_path: str) -> None:
        """
        Export current prompts to a specified file.
        """
        with self._lock:
            try:
                with open(export_path, 'w', encoding='utf-8') as file:
                    json.dump(self.prompts, file, indent=4, ensure_ascii=False)
                logger.info(f"ðŸ“¤ Prompts exported to {export_path}")
            except Exception as e:
                logger.error(f"âŒ Failed to export prompts: {e}")

    # ------------------------
    # PERSISTENT MEMORY MANAGEMENT
    # ------------------------
    def load_memory_state(self) -> None:
        """
        Load persistent memory state from file.
        """
        with self._lock:
            if os.path.exists(self.memory_file):
                try:
                    with open(self.memory_file, 'r', encoding='utf-8') as file:
                        self.memory_state = json.load(file)
                    logger.info(f"âœ… Loaded persistent memory from {self.memory_file}")
                except Exception as e:
                    logger.error(f"âŒ Failed to load memory state: {e}")
                    self.memory_state = {}
            else:
                logger.warning("âš ï¸ No memory file found. Starting with empty state.")
                self.memory_state = {}

    def save_memory_state(self) -> None:
        """
        Save the current memory state to a file asynchronously.
        """
        def save_task() -> None:
            with self._lock:
                try:
                    with open(self.memory_file, 'w', encoding='utf-8') as file:
                        json.dump(self.memory_state, file, indent=4, ensure_ascii=False)
                    logger.info(f"ðŸ’¾ Memory state saved to {self.memory_file}")
                except Exception as e:
                    logger.error(f"âŒ Failed to save memory state: {e}")

        threading.Thread(target=save_task, daemon=True).start()

    def parse_memory_updates(self, updates: Dict[str, Any]) -> None:
        """
        Parse structured memory updates from prompt responses and update the persistent memory.
        Expects a dict of updates, e.g.:
        {
            "skill_advancements": ["System Convergence +1"],
            "quests_completed": ["Stabilized Domain Alpha"],
            "architect_tier_progression": "Tier 2 Unlocked"
        }
        """
        logger.info("ðŸ” Parsing structured memory updates...")
        with self._lock:
            for key, value in updates.items():
                if isinstance(value, list):
                    self.memory_state.setdefault(key, [])
                    for item in value:
                        if item not in self.memory_state[key]:
                            self.memory_state[key].append(item)
                else:
                    self.memory_state[key] = value
            logger.info(f"âœ… Memory updated with: {updates}")
        self.save_memory_state()

    def review_memory_log(self) -> Dict[str, Any]:
        """
        Return the current persistent memory state.
        """
        logger.info("ðŸ“– Reviewing persistent memory log:")
        for key, value in self.memory_state.items():
            logger.info(f"{key}: {value}")
        return self.memory_state


# ---------------------------
# Example Usage
# ---------------------------
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)

    manager = AletheiaPromptManager(
        prompt_file="chat_mate/prompts.json",
        memory_file="chat_mate/persistent_memory.json"
    )
    manager.preview_prompts()

    # Add a custom prompt example
    manager.add_prompt(
        prompt_type="trading_insights",
        prompt_text="Summarize key trading strategies from this session...",
        model="gpt-4o-mini"
    )

    # Export prompts as backup
    manager.export_prompts(export_path="chat_mate/prompts_export.json")
    manager.save_prompts()

    # Simulate a memory update from a prompt response
    test_memory_update = {
        "skill_advancements": ["System Convergence +1"],
        "quests_completed": ["Stabilized Domain Alpha"],
        "architect_tier_progression": "Tier 2 Unlocked"
    }
    manager.parse_memory_updates(test_memory_update)
    manager.review_memory_log()